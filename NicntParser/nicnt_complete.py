#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NICNT å®Œæ•´è§£æå™¨ - å”¯ä¸€çš„å·¥ä½œè„šæœ¬
ç»“åˆæ‰€æœ‰åŠŸèƒ½ï¼šUTF-16æ–‡ä»¶åæå– + çœŸå®æ–‡ä»¶æ•°æ®æå– + æ­£ç¡®ç›®å½•ç»“æ„
"""

import os
import struct
import re
from pathlib import Path

class NicntCompleteParser:
    """å®Œæ•´çš„NICNTè§£æå™¨"""
    
    def __init__(self):
        self.file_paths = {}  # å­˜å‚¨UTF-16æå–çš„çœŸå®æ–‡ä»¶è·¯å¾„
        self.file_data_map = {}  # å­˜å‚¨æ–‡ä»¶æ•°æ®ä½ç½®
        
    def extract_real_filenames_from_toc(self, data: bytes, toc_pos: int):
        """ä»TOCä¸­æå–UTF-16ç¼–ç çš„çœŸå®æ–‡ä»¶å"""
        print("ğŸ” ä»TOCæå–çœŸå®æ–‡ä»¶å...")
        
        # UTF-16æ–‡ä»¶æ‰©å±•åæ¨¡å¼
        extensions = [
            (b'.\x00p\x00n\x00g\x00', '.png'),
            (b'.\x00d\x00b\x00', '.db'),
            (b'.\x00m\x00e\x00t\x00a\x00', '.meta'),
            (b'.\x00c\x00a\x00c\x00h\x00e\x00', '.cache'),
            (b'.\x00w\x00e\x00b\x00p\x00', '.webp')
        ]
        
        real_filenames = []
        for ext_bytes, ext_name in extensions:
            pos = toc_pos
            while True:
                pos = data.find(ext_bytes, pos)
                if pos == -1:
                    break
                
                # å‘å‰æœç´¢æ–‡ä»¶åå¼€å§‹ä½ç½®
                start = pos - 150
                while start < pos and start >= 0:
                    if (start % 2 == 0 and start + 1 < len(data) and
                        data[start + 1] == 0 and 32 <= data[start] <= 126):
                        char = chr(data[start])
                        if char == '.' or char.isalnum():
                            try:
                                utf16_data = data[start:pos + len(ext_bytes)]
                                filename = utf16_data.decode('utf-16le').rstrip('\x00')
                                if filename and '.' in filename and len(filename) <= 80:
                                    filename_clean = filename.replace('|', '[pipe]')
                                    self.file_paths[start] = filename_clean
                                    real_filenames.append(filename_clean)
                                    print(f"   âœ… {filename_clean}")
                                    break
                            except:
                                pass
                    start += 2
                pos += 1
        
        return real_filenames
    
    def find_file_data_positions(self, data: bytes):
        """åŸºäºHexåˆ†æçš„ç²¾ç¡®æ–‡ä»¶å®šä½"""
        print("ğŸ¯ åŸºäºHexåˆ†æç²¾ç¡®å®šä½æ–‡ä»¶æ•°æ®...")
        
        file_positions = []
        
        # SQLiteæ•°æ®åº“ - ä½¿ç”¨å¤´éƒ¨ä¿¡æ¯è®¡ç®—çœŸå®å¤§å°
        pos = 0
        db_index = 1
        while True:
            pos = data.find(b'SQLite format 3', pos)
            if pos == -1:
                break
            
            if pos + 100 < len(data):
                try:
                    header = data[pos:pos+100]
                    # è¯»å–é¡µå¤§å° (offset 16-17)
                    page_size_raw = struct.unpack('>H', header[16:18])[0]
                    page_size = 65536 if page_size_raw == 1 else page_size_raw
                    # è¯»å–æ•°æ®åº“é¡µæ•° (offset 28-31)
                    page_count = struct.unpack('>I', header[28:32])[0]
                    # è®¡ç®—çœŸå®æ–‡ä»¶å¤§å°
                    real_size = page_size * page_count
                    
                    if pos + real_size <= len(data):
                        file_positions.append({
                            'start': pos,
                            'end': pos + real_size,
                            'size': real_size,
                            'type': '.db',
                            'signature': b'SQLite format 3',
                            'real_size': True,
                            'db_index': db_index
                        })
                        print(f"   SQLite #{db_index}: {real_size:,} bytes @ 0x{pos:08x}")
                        db_index += 1
                except:
                    pass
            pos += 1
        
        # PNGæ–‡ä»¶ - æŸ¥æ‰¾IENDæ ‡è®°
        pos = 0
        png_index = 1
        while True:
            pos = data.find(b'\x89PNG', pos)
            if pos == -1:
                break
            
            end_pos = data.find(b'IEND', pos)
            if end_pos >= 0:
                end_pos += 8  # IEND + CRC
                file_positions.append({
                    'start': pos,
                    'end': end_pos,
                    'size': end_pos - pos,
                    'type': '.png',
                    'signature': b'\x89PNG',
                    'real_size': True,
                    'png_index': png_index
                })
                print(f"   PNG #{png_index}: {end_pos - pos:,} bytes @ 0x{pos:08x}")
                png_index += 1
            pos += 1
        
        # WEBPæ–‡ä»¶ - RIFFå®¹å™¨è§£æ
        pos = 0
        webp_index = 1
        while True:
            pos = data.find(b'RIFF', pos)
            if pos == -1:
                break
            
            if pos + 12 < len(data) and data[pos+8:pos+12] == b'WEBP':
                try:
                    webp_size = struct.unpack('<I', data[pos+4:pos+8])[0] + 8
                    if pos + webp_size <= len(data):
                        file_positions.append({
                            'start': pos,
                            'end': pos + webp_size,
                            'size': webp_size,
                            'type': '.webp',
                            'signature': b'RIFF',
                            'real_size': True,
                            'webp_index': webp_index
                        })
                        print(f"   WEBP #{webp_index}: {webp_size:,} bytes @ 0x{pos:08x}")
                        webp_index += 1
                except:
                    pass
            pos += 1
        
        # æŒ‰ä½ç½®æ’åº
        file_positions.sort(key=lambda x: x['start'])
        print(f"   æ€»è®¡å‘ç° {len(file_positions)} ä¸ªç²¾ç¡®æ•°æ®æ–‡ä»¶")
        return file_positions
    
    def find_meta_contents(self, data: bytes):
        """æŸ¥æ‰¾METAæ–‡ä»¶çš„çœŸå®XMLå†…å®¹"""
        print("ğŸ” æŸ¥æ‰¾METAæ–‡ä»¶çœŸå®å†…å®¹...")
        
        meta_contents = []
        pos = 0
        while True:
            pos = data.find(b'<?xml', pos)
            if pos == -1:
                break
            
            # æŸ¥æ‰¾XMLç»“æŸæ ‡è®°
            possible_endings = [
                b'</resource>',
                b'</ProductHints>',
                b'</metadata>',
                b'</soundinfos>'
            ]
            
            xml_end = -1
            for ending in possible_endings:
                end_pos = data.find(ending, pos)
                if end_pos != -1 and (xml_end == -1 or end_pos < xml_end):
                    xml_end = end_pos + len(ending)
            
            if xml_end != -1:
                xml_content = data[pos:xml_end]
                try:
                    xml_text = xml_content.decode('utf-8', errors='ignore')
                    
                    # å¤„ç†ä¸åŒç±»å‹çš„XMLå†…å®¹
                    if b'<resource' in xml_content:
                        # METAèµ„æºç±»å‹
                        name_match = re.search(r'<name>([^<]+)</name>', xml_text)
                        type_match = re.search(r'<type>([^<]+)</type>', xml_text)
                        
                        if name_match and type_match:
                            meta_contents.append({
                                'start': pos,
                                'end': xml_end,
                                'size': len(xml_content),
                                'content': xml_text,
                                'name': name_match.group(1),
                                'type': type_match.group(1),
                                'file_type': 'meta'
                            })
                            print(f"   META: {name_match.group(1)} ({type_match.group(1)}) - {len(xml_content)} bytes")
                    
                    elif b'<soundinfos' in xml_content:
                        # .db.cacheæ–‡ä»¶
                        meta_contents.append({
                            'start': pos,
                            'end': xml_end,
                            'size': len(xml_content),
                            'content': xml_text,
                            'name': 'cache',
                            'type': 'cache',
                            'file_type': 'cache'
                        })
                        print(f"   CACHE: soundinfos - {len(xml_content)} bytes")
                    
                except Exception as e:
                    pass
            
            pos += 1
        
        print(f"   æ€»è®¡å‘ç° {len(meta_contents)} ä¸ªMETAæ–‡ä»¶")
        return meta_contents
    
    def match_filenames_to_data(self, real_filenames, file_positions):
        """åŒ¹é…çœŸå®æ–‡ä»¶ååˆ°æ–‡ä»¶æ•°æ®"""
        print("ğŸ”— åŒ¹é…æ–‡ä»¶ååˆ°æ•°æ®...")
        
        matched_files = []
        
        # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„
        png_files = [f for f in real_filenames if f.endswith('.png')]
        db_files = [f for f in real_filenames if f.endswith('.db')]
        meta_files = [f for f in real_filenames if f.endswith('.meta')]
        cache_files = [f for f in real_filenames if f.endswith('.cache')]
        webp_files = [f for f in real_filenames if f.endswith('.webp')]
        
        png_positions = [p for p in file_positions if p['type'] == '.png']
        db_positions = [p for p in file_positions if p['type'] == '.db']
        webp_positions = [p for p in file_positions if p['type'] == '.webp']
        
        # åŒ¹é…PNGæ–‡ä»¶
        for i, png_name in enumerate(png_files):
            if i < len(png_positions):
                matched_files.append({
                    'name': png_name,
                    'data_pos': png_positions[i]
                })
        
        # åŒ¹é…DBæ–‡ä»¶
        for i, db_name in enumerate(db_files):
            if i < len(db_positions):
                matched_files.append({
                    'name': db_name,
                    'data_pos': db_positions[i]
                })
        
        # åŒ¹é…WEBPæ–‡ä»¶
        for i, webp_name in enumerate(webp_files):
            if i < len(webp_positions):
                matched_files.append({
                    'name': webp_name,
                    'data_pos': webp_positions[i]
                })
        
        # METAå’ŒCACHEæ–‡ä»¶æ²¡æœ‰äºŒè¿›åˆ¶æ•°æ®ï¼Œåˆ›å»ºå ä½æ–‡ä»¶
        for meta_name in meta_files:
            matched_files.append({
                'name': meta_name,
                'data_pos': {'start': 0, 'end': 0, 'size': 0, 'type': '.meta'}
            })
        
        for cache_name in cache_files:
            matched_files.append({
                'name': cache_name,
                'data_pos': {'start': 0, 'end': 0, 'size': 0, 'type': '.cache'}
            })
        
        print(f"   åŒ¹é…æˆåŠŸ {len(matched_files)} ä¸ªæ–‡ä»¶")
        return matched_files
    
    def create_directory_structure(self, output_dir, filename):
        """æ ¹æ®æ­£ç¡®çš„ç»“æ„ï¼šResourcesç›®å½•ä¸‹ç›´æ¥æ”¾æ–‡ä»¶ï¼Œä¿æŒ[pipe]æ–‡ä»¶å"""
        # æ‰€æœ‰æ–‡ä»¶éƒ½ç›´æ¥æ”¾åœ¨Resourcesç›®å½•ä¸‹ï¼Œæ–‡ä»¶åä¿æŒ[pipe]æ ¼å¼
        resources_dir = os.path.join(output_dir, "Resources")
        os.makedirs(resources_dir, exist_ok=True)
        return resources_dir, filename
    
    def extract_complete_nicnt(self, nicnt_path, output_base_name):
        """å®Œæ•´çš„NICNTæ–‡ä»¶æå–"""
        print("ğŸš€ NICNTå®Œæ•´è§£æå™¨å¯åŠ¨")
        print("=" * 60)
        
        # è¯»å–æ–‡ä»¶
        with open(nicnt_path, 'rb') as f:
            data = f.read()
        
        print(f"ğŸ“ æºæ–‡ä»¶: {nicnt_path}")
        print(f"ğŸ“Š å¤§å°: {len(data):,} bytes")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = f"/mnt/c/Code/Electron/KontaktMax/Test/{output_base_name}_complete"
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
        
        # æŸ¥æ‰¾TOCä½ç½®
        toc_marker = b"/\\ NI FC TOC  /\\"
        toc_pos = data.find(toc_marker)
        if toc_pos == -1:
            print("âŒ æœªæ‰¾åˆ°TOCæ ‡è¯†ç¬¦")
            return
        
        print(f"ğŸ” TOCä½ç½®: {toc_pos}")
        
        # æå–çœŸå®æ–‡ä»¶å
        real_filenames = self.extract_real_filenames_from_toc(data, toc_pos)
        
        # æŸ¥æ‰¾æ–‡ä»¶æ•°æ®ä½ç½®
        file_positions = self.find_file_data_positions(data)
        
        # æŸ¥æ‰¾METAå†…å®¹
        meta_contents = self.find_meta_contents(data)
        
        # åŒ¹é…æ–‡ä»¶ååˆ°æ•°æ®
        matched_files = self.match_filenames_to_data(real_filenames, file_positions)
        
        # æ·»åŠ METAæ–‡ä»¶å’ŒCACHEæ–‡ä»¶åˆ°åŒ¹é…ç»“æœ
        for meta in meta_contents:
            if meta['file_type'] == 'cache':
                # .db.cacheæ–‡ä»¶
                cache_filename = '.db.cache'
                if cache_filename in real_filenames:
                    matched_files.append({
                        'name': cache_filename,
                        'data_pos': {
                            'start': meta['start'],
                            'end': meta['end'],
                            'size': meta['size'],
                            'type': '.cache',
                            'content': meta['content']
                        }
                    })
                    print(f"   âœ… åŒ¹é…CACHE: {cache_filename}")
            else:
                # METAæ–‡ä»¶
                if meta['type'] == '_DatabaseResources':
                    meta_filename = f".PAResources[pipe]_DatabaseResources[pipe]{meta['name']}[pipe]{meta['name']}.meta"
                elif meta['type'] == 'database':
                    meta_filename = f".PAResources[pipe]database[pipe]PAL[pipe]{meta['name']}.meta"
                elif meta['type'] == 'image':
                    meta_filename = f".PAResources[pipe]image[pipe]40s Very Own - Drums[pipe]{meta['name']}.meta"
                else:
                    meta_filename = f"{meta['name']}.meta"
                
                # æ£€æŸ¥æ˜¯å¦åœ¨çœŸå®æ–‡ä»¶ååˆ—è¡¨ä¸­
                if meta_filename in real_filenames:
                    matched_files.append({
                        'name': meta_filename,
                        'data_pos': {
                            'start': meta['start'],
                            'end': meta['end'],
                            'size': meta['size'],
                            'type': '.meta',
                            'content': meta['content']
                        }
                    })
                    print(f"   âœ… åŒ¹é…META: {meta_filename}")
        
        # æå–XMLå’Œäº§å“å
        xml_start = data.find(b'<?xml')
        product_name = output_base_name
        if xml_start >= 0:
            xml_end = data.find(b'</ProductHints>', xml_start)
            if xml_end >= 0:
                xml_end += len(b'</ProductHints>')
                xml_data = data[xml_start:xml_end]
                xml_content = xml_data.decode('utf-8', errors='ignore')
                
                name_match = re.search(r'<Name>([^<]+)</Name>', xml_content)
                if name_match:
                    product_name = name_match.group(1).strip()
                
                # ä¿å­˜XMLæ–‡ä»¶
                xml_path = os.path.join(output_dir, f"{product_name}.xml")
                with open(xml_path, 'wb') as f:
                    f.write(xml_data)
                print(f"   âœ… {product_name}.xml ({len(xml_data)} bytes)")
        
        # åˆ›å»ºContentVersion.txt
        content_version_path = os.path.join(output_dir, "ContentVersion.txt")
        with open(content_version_path, 'w', encoding='utf-8') as f:
            f.write("1.0.0\n")
        print(f"   âœ… ContentVersion.txt")
        
        # ä¿å­˜æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
        saved_count = 2  # XML + ContentVersion
        print(f"\nğŸ’¾ ä¿å­˜æ–‡ä»¶åˆ°æ­£ç¡®çš„ç›®å½•ç»“æ„...")
        
        for file_info in matched_files:
            filename = file_info['name']
            data_pos = file_info['data_pos']
            
            try:
                # åˆ›å»ºç›®å½•ç»“æ„
                target_dir, final_filename = self.create_directory_structure(output_dir, filename)
                file_path = os.path.join(target_dir, final_filename)
                
                if (data_pos['type'] == '.meta' or data_pos['type'] == '.cache') and 'content' in data_pos:
                    # META/CACHEæ–‡ä»¶ï¼Œä¿å­˜çœŸå®XMLå†…å®¹
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(data_pos['content'])
                    file_type_name = "çœŸå®META" if data_pos['type'] == '.meta' else "çœŸå®CACHE"
                    print(f"   âœ… {filename} ({len(data_pos['content'])} bytes) [{file_type_name}]")
                elif data_pos['size'] > 0:
                    # æœ‰å®é™…äºŒè¿›åˆ¶æ•°æ®çš„æ–‡ä»¶
                    file_data = data[data_pos['start']:data_pos['end']]
                    with open(file_path, 'wb') as f:
                        f.write(file_data)
                    print(f"   âœ… {filename} ({len(file_data):,} bytes)")
                else:
                    # CACHEç­‰æ–‡ä»¶ï¼Œåˆ›å»ºå ä½ç¬¦
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(f"# {filename} placeholder\n")
                    print(f"   âœ… {filename} (placeholder)")
                
                saved_count += 1
                
            except Exception as e:
                print(f"   âŒ ä¿å­˜ {filename} å¤±è´¥: {e}")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
        print(f"\nğŸ“ˆ æå–å®Œæˆ!")
        print(f"   â€¢ æ€»æ–‡ä»¶æ•°: {saved_count}")
        print(f"   â€¢ çœŸå®æ–‡ä»¶å: {len(real_filenames)}")
        print(f"   â€¢ äº§å“å: {product_name}")
        
        print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°:")
        print(f"ğŸ“‚ {output_dir}")
        
        return output_dir

def main():
    """ä¸»å‡½æ•°"""
    parser = NicntCompleteParser()
    
    nicnt_file = "/mnt/c/Code/Electron/KontaktMax/Test/40s Very Own - Drums.nicnt"
    base_name = "40s Very Own - Drums"
    
    result_dir = parser.extract_complete_nicnt(nicnt_file, base_name)
    
    print(f"\nâœ¨ ä½¿ç”¨Windowsæ–‡ä»¶ç®¡ç†å™¨æŸ¥çœ‹ç»“æœ:")
    windows_path = result_dir.replace('/mnt/c/', 'C:\\').replace('/', '\\')
    print(f"ğŸ“ {windows_path}")

if __name__ == "__main__":
    main()